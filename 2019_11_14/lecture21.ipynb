{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mud card\n",
    "- **Why is cv score higer than train score in some cases?**\n",
    "   - we use MSE as our evaluation metric, so the cv score should normally be higher than the train score\n",
    "   - the unusual thing is when the cv score is smaller than the train score\n",
    "      - we work with small datasets due to the hub's limited computational resources\n",
    "      - unlucky splits happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **For k-fold, when shuffle is true, when is the data shuffled? is the data shuffled before splitting into k folds? but isn't data shuffled before?**\n",
    "   - the data is shuffled first, then split into folds\n",
    "   - train_test_split by default shuffles the data so if you use train_test_split first, it's OK to not shuffle in KFold\n",
    "   - ALWAYS CHECK THAT THE CODE DOES WHAT YOU INTEND IT TO DO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **how is the deviation of k-fold test mse smaller than the basic pipeline?**\n",
    "   - KFold CV was run only once, so we only had one set of points in test\n",
    "      - the only source of uncertainty came from changing the CV fold\n",
    "   - we ran the basic ML pipeline 10 times, so we had 10 different train/CV/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **What is the meaning of \"rank_test_score\"?**\n",
    "   - rank_test_score column in the results tells you what GridSearchCV believes to be the best hyperparameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "np.random.seed(10)\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "n_samples = 100\n",
    "\n",
    "X = np.random.rand(n_samples)\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold(X,y,random_state,n_folds):\n",
    "    # split the data\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    CV_scores = []\n",
    "    test_scores = []\n",
    "    # k folds - each fold will give us a CV and a test score\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    for train_index, CV_index in kf.split(X_other,y_other):\n",
    "        X_train, X_CV = X_other[train_index], X_other[CV_index]\n",
    "        y_train, y_CV = y_other[train_index], y_other[CV_index]\n",
    "        # simple preprocessing\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_c = scaler.transform(X_CV)\n",
    "        X_t = scaler.transform(X_test)\n",
    "        # tune ridge hyper-parameter, alpha\n",
    "        alpha = np.logspace(-5,2,num=8)\n",
    "        train_score = []\n",
    "        CV_score = []\n",
    "        regs = []\n",
    "        for a in alpha:\n",
    "            reg = Ridge(alpha = a)\n",
    "            reg.fit(X_train,y_train)\n",
    "            train_score.append(mean_squared_error(y_train,reg.predict(X_train)))\n",
    "            CV_score.append(mean_squared_error(y_CV,reg.predict(X_c)))\n",
    "            regs.append(reg)\n",
    "        # find the best alpha in this fold\n",
    "        best_alpha = alpha[np.argmin(CV_score)]\n",
    "        # grab the best model\n",
    "        reg = regs[np.argmin(CV_score)]\n",
    "        CV_scores.append(np.min(CV_score))\n",
    "        # calculate test score using thee best model\n",
    "        test_scores.append(mean_squared_error(y_test,reg.predict(X_t)))\n",
    "    return CV_scores,test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    scaler = StandardScaler()\n",
    "    pipe = make_pipeline(scaler,Ridge())\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'ridge__alpha': np.logspace(-3,4,num=8)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(mean_squared_error,greater_is_better=False),\n",
    "                        cv=kf, return_train_score = True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    return grid, grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MSE: 0.19 +/- 0.03\n",
      "test MSE: 0.16\n",
      "Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('ridge',\n",
      "                 Ridge(alpha=0.1, copy_X=True, fit_intercept=True,\n",
      "                       max_iter=None, normalize=False, random_state=None,\n",
      "                       solver='auto', tol=0.001))],\n",
      "         verbose=False)\n",
      "-0.18765006501383993\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'ridge__alpha': 0.001}</td>\n",
       "      <td>-0.202300</td>\n",
       "      <td>-0.157711</td>\n",
       "      <td>-0.168699</td>\n",
       "      <td>-0.160049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187654</td>\n",
       "      <td>0.034810</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.180344</td>\n",
       "      <td>-0.191596</td>\n",
       "      <td>-0.188761</td>\n",
       "      <td>-0.192012</td>\n",
       "      <td>-0.168994</td>\n",
       "      <td>-0.184341</td>\n",
       "      <td>0.008747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'ridge__alpha': 0.01}</td>\n",
       "      <td>-0.202294</td>\n",
       "      <td>-0.157719</td>\n",
       "      <td>-0.168705</td>\n",
       "      <td>-0.160029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187654</td>\n",
       "      <td>0.034814</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.180344</td>\n",
       "      <td>-0.191596</td>\n",
       "      <td>-0.188761</td>\n",
       "      <td>-0.192012</td>\n",
       "      <td>-0.168994</td>\n",
       "      <td>-0.184341</td>\n",
       "      <td>0.008747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'ridge__alpha': 0.1}</td>\n",
       "      <td>-0.202237</td>\n",
       "      <td>-0.157799</td>\n",
       "      <td>-0.168761</td>\n",
       "      <td>-0.159828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187650</td>\n",
       "      <td>0.034859</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.180344</td>\n",
       "      <td>-0.191597</td>\n",
       "      <td>-0.188762</td>\n",
       "      <td>-0.192013</td>\n",
       "      <td>-0.168995</td>\n",
       "      <td>-0.184342</td>\n",
       "      <td>0.008747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1</td>\n",
       "      <td>{'ridge__alpha': 1.0}</td>\n",
       "      <td>-0.201740</td>\n",
       "      <td>-0.158650</td>\n",
       "      <td>-0.169361</td>\n",
       "      <td>-0.157909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187673</td>\n",
       "      <td>0.035312</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.180407</td>\n",
       "      <td>-0.191656</td>\n",
       "      <td>-0.188824</td>\n",
       "      <td>-0.192083</td>\n",
       "      <td>-0.169056</td>\n",
       "      <td>-0.184405</td>\n",
       "      <td>0.008748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>10</td>\n",
       "      <td>{'ridge__alpha': 10.0}</td>\n",
       "      <td>-0.202714</td>\n",
       "      <td>-0.170812</td>\n",
       "      <td>-0.178430</td>\n",
       "      <td>-0.145902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192327</td>\n",
       "      <td>0.040060</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.185235</td>\n",
       "      <td>-0.196205</td>\n",
       "      <td>-0.193658</td>\n",
       "      <td>-0.197511</td>\n",
       "      <td>-0.173772</td>\n",
       "      <td>-0.189276</td>\n",
       "      <td>0.008851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ridge__alpha': 100.0}</td>\n",
       "      <td>-0.299603</td>\n",
       "      <td>-0.303486</td>\n",
       "      <td>-0.282612</td>\n",
       "      <td>-0.179732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289302</td>\n",
       "      <td>0.064467</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.279937</td>\n",
       "      <td>-0.285426</td>\n",
       "      <td>-0.288467</td>\n",
       "      <td>-0.303964</td>\n",
       "      <td>-0.266270</td>\n",
       "      <td>-0.284813</td>\n",
       "      <td>0.012232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'ridge__alpha': 1000.0}</td>\n",
       "      <td>-0.454587</td>\n",
       "      <td>-0.475300</td>\n",
       "      <td>-0.419325</td>\n",
       "      <td>-0.279924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.430692</td>\n",
       "      <td>0.082690</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.416955</td>\n",
       "      <td>-0.414514</td>\n",
       "      <td>-0.425639</td>\n",
       "      <td>-0.457985</td>\n",
       "      <td>-0.400098</td>\n",
       "      <td>-0.423038</td>\n",
       "      <td>0.019308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'ridge__alpha': 10000.0}</td>\n",
       "      <td>-0.486653</td>\n",
       "      <td>-0.509482</td>\n",
       "      <td>-0.446598</td>\n",
       "      <td>-0.302210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.459481</td>\n",
       "      <td>0.085772</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.444815</td>\n",
       "      <td>-0.440761</td>\n",
       "      <td>-0.453530</td>\n",
       "      <td>-0.489302</td>\n",
       "      <td>-0.427309</td>\n",
       "      <td>-0.451143</td>\n",
       "      <td>0.020869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001283      0.000445         0.000439        0.000177   \n",
       "1       0.000757      0.000086         0.000250        0.000008   \n",
       "2       0.000871      0.000126         0.000379        0.000062   \n",
       "3       0.000792      0.000164         0.000258        0.000033   \n",
       "4       0.000729      0.000075         0.000252        0.000013   \n",
       "5       0.000684      0.000038         0.000283        0.000070   \n",
       "6       0.000764      0.000087         0.000250        0.000014   \n",
       "7       0.000934      0.000243         0.000329        0.000114   \n",
       "\n",
       "  param_ridge__alpha                     params  split0_test_score  \\\n",
       "0              0.001    {'ridge__alpha': 0.001}          -0.202300   \n",
       "1               0.01     {'ridge__alpha': 0.01}          -0.202294   \n",
       "2                0.1      {'ridge__alpha': 0.1}          -0.202237   \n",
       "3                  1      {'ridge__alpha': 1.0}          -0.201740   \n",
       "4                 10     {'ridge__alpha': 10.0}          -0.202714   \n",
       "5                100    {'ridge__alpha': 100.0}          -0.299603   \n",
       "6               1000   {'ridge__alpha': 1000.0}          -0.454587   \n",
       "7              10000  {'ridge__alpha': 10000.0}          -0.486653   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0          -0.157711          -0.168699          -0.160049  ...   \n",
       "1          -0.157719          -0.168705          -0.160029  ...   \n",
       "2          -0.157799          -0.168761          -0.159828  ...   \n",
       "3          -0.158650          -0.169361          -0.157909  ...   \n",
       "4          -0.170812          -0.178430          -0.145902  ...   \n",
       "5          -0.303486          -0.282612          -0.179732  ...   \n",
       "6          -0.475300          -0.419325          -0.279924  ...   \n",
       "7          -0.509482          -0.446598          -0.302210  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0        -0.187654        0.034810                3           -0.180344   \n",
       "1        -0.187654        0.034814                2           -0.180344   \n",
       "2        -0.187650        0.034859                1           -0.180344   \n",
       "3        -0.187673        0.035312                4           -0.180407   \n",
       "4        -0.192327        0.040060                5           -0.185235   \n",
       "5        -0.289302        0.064467                6           -0.279937   \n",
       "6        -0.430692        0.082690                7           -0.416955   \n",
       "7        -0.459481        0.085772                8           -0.444815   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0           -0.191596           -0.188761           -0.192012   \n",
       "1           -0.191596           -0.188761           -0.192012   \n",
       "2           -0.191597           -0.188762           -0.192013   \n",
       "3           -0.191656           -0.188824           -0.192083   \n",
       "4           -0.196205           -0.193658           -0.197511   \n",
       "5           -0.285426           -0.288467           -0.303964   \n",
       "6           -0.414514           -0.425639           -0.457985   \n",
       "7           -0.440761           -0.453530           -0.489302   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0           -0.168994         -0.184341         0.008747  \n",
       "1           -0.168994         -0.184341         0.008747  \n",
       "2           -0.168995         -0.184342         0.008747  \n",
       "3           -0.169056         -0.184405         0.008748  \n",
       "4           -0.173772         -0.189276         0.008851  \n",
       "5           -0.266270         -0.284813         0.012232  \n",
       "6           -0.400098         -0.423038         0.019308  \n",
       "7           -0.427309         -0.451143         0.020869  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid, test_score = ML_pipeline_kfold_GridSearchCV(X[:,np.newaxis],y,42,5)\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "print('CV MSE:',-np.around(results[results['rank_test_score'] == 1]['mean_test_score'].values[0],2),\\\n",
    "      '+/-',np.around(results[results['rank_test_score'] == 1]['std_test_score'].values[0],2))\n",
    "print('test MSE:',-np.around(test_score,2))\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_index_)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross Validation with iid and non-iid data\n",
    "By the end of this lecture, you will be able to\n",
    "- use GridSearchCV with pipelines\n",
    "- apply stratified splits to imbalanced data\n",
    "- split based on group ID and time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='lightgray'>Cross Validation with iid and non-iid data</font>\n",
    "<font color='lightgray'>By the end of this lecture, you will be able to</font>\n",
    "- **use GridSearchCV with pipelines**\n",
    "- <font color='lightgray'>apply stratified splits to imbalanced data</font>\n",
    "- <font color='lightgray'>split based on group ID and time</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Some notable differences between my KFold and KFold with GridSearchCV\n",
    "- if multiple parameters give an equally good CV score, GridSearchCV returns the largest\n",
    "   - my function returns the smallest\n",
    "- GridSearchCV calculates only one test score\n",
    "   - my function returns n_folds test scores\n",
    "   - the GridSearchCV approach refits the best model to X_other and y_other and that model is used to calculate the test score\n",
    "   - it's unclear which one is better\n",
    "      - my approach allows to calculate some uncertainty due to splitting (not on test)\n",
    "      - the GridSearchCV approach returns one test score but it is based on more data (likely more accurate)\n",
    "- 7 lines of code in GridSearchCV\n",
    "   - 28 lines of code in my function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Estimate the uncertainty from random test sets in KFold CV\n",
    "### Exercise 1 \n",
    "Calculate the test score for 10 different random splits. What's the mean and std test score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='lightgray'>Cross Validation with iid and non-iid data</font>\n",
    "<font color='lightgray'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='lightgray'>use GridSearchCV with pipelines</font>\n",
    "- **apply stratified splits to imbalanced data**\n",
    "- <font color='lightgray'>split based on group ID and time</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Imbalanced data: use stratified folds\n",
    "<center><img src=\"figures/stratified_kfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StratifiedKFold in module sklearn.model_selection._split:\n",
      "\n",
      "class StratifiedKFold(_BaseKFold)\n",
      " |  Stratified K-Folds cross-validator\n",
      " |  \n",
      " |  Provides train/test indices to split data in train/test sets.\n",
      " |  \n",
      " |  This cross-validation object is a variation of KFold that returns\n",
      " |  stratified folds. The folds are made by preserving the percentage of\n",
      " |  samples for each class.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=3\n",
      " |      Number of folds. Must be at least 2.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          ``n_splits`` default value will change from 3 to 5 in v0.22.\n",
      " |  \n",
      " |  shuffle : boolean, optional\n",
      " |      Whether to shuffle each class's samples before splitting into batches.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default=None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`. Used when ``shuffle`` == True.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import StratifiedKFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      " |  >>> y = np.array([0, 0, 1, 1])\n",
      " |  >>> skf = StratifiedKFold(n_splits=2)\n",
      " |  >>> skf.get_n_splits(X, y)\n",
      " |  2\n",
      " |  >>> print(skf)  # doctest: +NORMALIZE_WHITESPACE\n",
      " |  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      " |  >>> for train_index, test_index in skf.split(X, y):\n",
      " |  ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...    X_train, X_test = X[train_index], X[test_index]\n",
      " |  ...    y_train, y_test = y[train_index], y[test_index]\n",
      " |  TRAIN: [1 3] TEST: [0 2]\n",
      " |  TRAIN: [0 2] TEST: [1 3]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Train and test sizes may be different in each fold, with a difference of at\n",
      " |  most ``n_classes``.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StratifiedKFold\n",
      " |      _BaseKFold\n",
      " |      BaseCrossValidator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_splits='warn', shuffle=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  split(self, X, y, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training data, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |          Note that providing ``y`` is sufficient to generate the splits and\n",
      " |          hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
      " |          ``X`` instead of actual training data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          The target variable for supervised learning problems.\n",
      " |          Stratification is done based on the y labels.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Randomized CV splitters may return different results for each call of\n",
      " |      split. You can make the results identical by setting ``random_state``\n",
      " |      to an integer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "help(StratifiedKFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stratified train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float, int or None, optional (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float, int, or None, (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "    \n",
      "    shuffle : boolean, optional (default=True)\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like or None (default=None)\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split) # give the class labels to the stratify parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='lightgray'>Cross Validation with iid and non-iid data</font>\n",
    "<font color='lightgray'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='lightgray'>use GridSearchCV with pipelines</font>\n",
    "- <font color='lightgray'>apply stratified splits to imbalanced data</font>\n",
    "- **split based on group ID and time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When the iid assumption breaks down\n",
    "- What is the intended use of the model? What is it supposed to do/predict?\n",
    "- What data do you have available at that time?\n",
    "- Your cross validation must simulate the intended use of the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An example: seizure project\n",
    "- you can read the publication [here](https://ieeexplore.ieee.org/document/8857552)\n",
    "- classification problem:\n",
    "   - epileptic seizures vs. non-epileptic psychogenic seizures\n",
    "- data from empatica wrist sensor\n",
    "   - heart rate, skin temperature, EDA, blood volume pressure, acceleration\n",
    "- data collection:\n",
    "   - patients come to the hospital for a few days\n",
    "   - eeg and video recording to determine seizure type\n",
    "   - wrist sensor data is collected\n",
    "- question:\n",
    "   - Can we use the wrist sensor data to differentiate the two seizure types on new patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    patient ID            seizure_ID  ACC_mean  BVP_mean  EDA_mean    HR_mean  \\\n",
      "5           32  ID32__day3_arm_1_sz1  1.028539 -0.092102  0.112795  64.748167   \n",
      "6           32  ID32__day3_arm_1_sz1  1.027986  0.745437  0.130486  63.715667   \n",
      "7           32  ID32__day2_arm_1_sz0  1.002146  0.150810  0.189272  61.838500   \n",
      "8           32  ID32__day2_arm_1_sz0  1.005410  0.482859  1.226038  66.240833   \n",
      "9           32  ID32__day1_arm_1_sz0  0.997017 -0.925122  0.200990  56.103667   \n",
      "10          32  ID32__day1_arm_1_sz0  1.009207  1.618456  1.679754  64.668167   \n",
      "27          32  ID32__day1_arm_1_sz0  1.000290  0.046690  0.123165  54.289500   \n",
      "28          32  ID32__day1_arm_1_sz0  1.010351  0.125039  0.471180  65.060667   \n",
      "29          32  ID32__day2_arm_1_sz0  1.018163  0.254302  0.206010  61.875833   \n",
      "30          32  ID32__day2_arm_1_sz0  1.016785  1.242893  0.954649  66.216167   \n",
      "34          32  ID32__day3_arm_1_sz1  1.008867  0.070180  0.195966  65.995667   \n",
      "35          32  ID32__day3_arm_1_sz1  1.009554  0.222872  0.229909  63.871000   \n",
      "58          32  ID32__day3_arm_1_sz0  1.008873 -0.550857  0.177822  67.750833   \n",
      "79          32  ID32__day3_arm_1_sz0  1.026840  0.355953  0.205273  69.124667   \n",
      "\n",
      "    TEMP_mean  ACC_stdev   BVP_stdev  EDA_stdev  ...  BVP_50th  EDA_50th  \\\n",
      "5   36.944833   0.007469   36.486091   0.003905  ...     1.815  0.112710   \n",
      "6   36.676333   0.028190   84.964155   0.018598  ...     2.210  0.131921   \n",
      "7   38.600333   0.003747   64.194294   0.024278  ...     6.985  0.186026   \n",
      "8   39.296083   0.035257  165.665784   0.891139  ...     1.140  1.062333   \n",
      "9   34.656667   0.022648   77.013336   0.132008  ...     3.800  0.142159   \n",
      "10  34.678000   0.046047  146.515297   0.438236  ...     5.585  1.690537   \n",
      "27  38.467417   0.019826   51.176639   0.014530  ...     7.765  0.124259   \n",
      "28  38.448000   0.077142   61.205657   0.156170  ...     3.290  0.510114   \n",
      "29  37.681583   0.006805   40.982246   0.017099  ...     1.455  0.202632   \n",
      "30  37.979500   0.032493  219.277839   0.612229  ...    -5.785  1.028171   \n",
      "34  40.659458   0.021812   49.981175   0.013259  ...     3.480  0.198570   \n",
      "35  40.481333   0.048531   37.409681   0.031963  ...     0.695  0.228676   \n",
      "58  39.906667   0.021431   27.472002   0.003085  ...     1.955  0.178073   \n",
      "79  34.490167   0.008165   40.742936   0.003550  ...     3.090  0.206207   \n",
      "\n",
      "    HR_50th  TEMP_50th  ACC_75th  BVP_75th  EDA_75th  HR_75th  TEMP_75th  \\\n",
      "5    65.060      36.95  1.029947   16.3725  0.115591  65.8175     36.990   \n",
      "6    62.175      36.81  1.029947   21.1625  0.147611  66.2100     36.840   \n",
      "7    61.840      38.61  1.006085   43.8850  0.209086  61.9000     38.790   \n",
      "8    62.325      39.37  1.008872   49.4325  2.313129  71.0625     39.390   \n",
      "9    56.110      34.66  0.996821   35.2700  0.176739  56.6050     34.660   \n",
      "10   65.790      34.66  1.021497   70.4800  1.998868  67.7725     34.735   \n",
      "27   53.960      38.49  1.002073   39.8525  0.133226  54.7425     38.500   \n",
      "28   65.285      38.45  1.014302   25.4625  0.577047  69.4975     38.530   \n",
      "29   61.910      37.68  1.022811   29.2125  0.219282  61.9300     37.750   \n",
      "30   64.700      38.00  1.022811   65.5000  1.503002  69.5725     38.030   \n",
      "34   66.145      40.68  1.013700   13.1300  0.199852  67.0425     40.710   \n",
      "35   64.395      40.49  1.016106   12.9650  0.260383  65.9625     40.530   \n",
      "58   68.170      39.93  1.015264   17.8625  0.179354  68.5725     40.030   \n",
      "79   69.810      34.37  1.033260   13.4550  0.207488  70.0000     34.680   \n",
      "\n",
      "    label  \n",
      "5     0.0  \n",
      "6     0.0  \n",
      "7     0.0  \n",
      "8     0.0  \n",
      "9     0.0  \n",
      "10    0.0  \n",
      "27    0.0  \n",
      "28    0.0  \n",
      "29    0.0  \n",
      "30    0.0  \n",
      "34    0.0  \n",
      "35    0.0  \n",
      "58    0.0  \n",
      "79    0.0  \n",
      "\n",
      "[14 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/seizure_data.csv')\n",
    "print(df[df['patient ID'] == 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance: 0.6884057971014492\n"
     ]
    }
   ],
   "source": [
    "y = df['label']\n",
    "patient_ID = df['patient ID']\n",
    "seizure_ID = df['seizure_ID']\n",
    "X = df.drop(columns=['patient ID','seizure_ID','label'])\n",
    "classes, counts = np.unique(y,return_counts=True)\n",
    "print('balance:',np.max(counts/len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "def ML_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    scaler = StandardScaler()\n",
    "    pipe = make_pipeline(scaler,SVC())\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'svc__C': np.logspace(-3,4,num=8),'svc__gamma': np.logspace(-3,4,num=8)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    return grid, grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.9136363636363637\n",
      "test score: 0.9285714285714286\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.9454545454545454\n",
      "test score: 0.9285714285714286\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.9227272727272727\n",
      "test score: 0.9464285714285714\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.9363636363636364\n",
      "test score: 0.9285714285714286\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.9454545454545454\n",
      "test score: 0.9107142857142857\n",
      "test accuracy: 0.93 +/- 0.01\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(5):\n",
    "    grid, test_score = ML_pipeline_kfold_GridSearchCV(X,y,i*42,5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This is wrong! A very bad case of data leakage!\n",
    "- the textbook case of information leakage!\n",
    "- if we just do KFold CV blindly, the points from the same patient end up in different sets\n",
    "   - when you deploy the model and apply it to data from new patients, that patient's data will be seen for the first time\n",
    "- the ML pipeline needs to mimic the intended use of the model!\n",
    "   - we want to split the points based on the patient ID!\n",
    "   - we want all points from the same patient to be in either train/CV/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Group-based split: GroupKFold\n",
    "<center><img src=\"figures/groupkfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "def ML_pipeline_groups_GridSearchCV(X,y,groups,random_state,n_folds):\n",
    "    # create a test set based on groups\n",
    "    splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=random_state)\n",
    "    for i_other,i_test in splitter.split(X, y, groups):\n",
    "        X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "    # check the split\n",
    "#     print(pd.unique(groups))\n",
    "#     print(pd.unique(groups_other))\n",
    "#     print(pd.unique(groups_test))\n",
    "    # splitter for _other\n",
    "    kf = GroupKFold(n_splits=n_folds)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    scaler = StandardScaler()\n",
    "    pipe = make_pipeline(scaler,SVC())\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'svc__C': np.logspace(-3,4,num=8),'svc__gamma': np.logspace(-3,4,num=8)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other, groups_other)\n",
    "    return grid, grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8143459915611815\n",
      "test score: 0.6410256410256411\n",
      "{'svc__C': 10000.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.6455696202531646\n",
      "test score: 0.5847457627118644\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.6494845360824743\n",
      "test score: 0.9390243902439024\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.7907949790794979\n",
      "test score: 0.43243243243243246\n",
      "{'svc__C': 10000.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.6756756756756757\n",
      "test score: 0.8901098901098901\n",
      "test accuracy: 0.7 +/- 0.19\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(5):\n",
    "    grid, test_score = ML_pipeline_groups_GridSearchCV(X,y,patient_ID,i*42,5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The takeaway\n",
    "- an incorrect cross validation pipeline gives misleading results\n",
    "   - usually the model appears to be pretty accurate\n",
    "   - but the performance is poor when the model is deployed\n",
    "- this can be avoided by a careful cross validation pipeline\n",
    "   - think about how your model will be used\n",
    "   - mimic that future use in CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data leakage in time series data is similar!\n",
    "- do NOT use information in CV which will not be available once your model is deployed\n",
    "   - don't use future information!\n",
    "   \n",
    "<center><img src=\"figures/timeseriessplit.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now you can\n",
    "- use GridSearchCV with pipelines\n",
    "- apply stratified splits to imbalanced data\n",
    "- split based on group ID and time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
