{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1) We will create a kfold CV pipeline for the heart disease dataset you worked with during the midterm exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1a) Read in the data and drop the rows with missing values. Remember that the dataset does not contain the feature names! Separate out the feature matrix (X) and the target variable (y). What is the balance of this dataset (the baseline accuracy)? (2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "\n",
      "   slope   ca thal  \n",
      "0    3.0  0.0  6.0  \n",
      "1    2.0  3.0  3.0  \n",
      "2    2.0  2.0  7.0  \n",
      "3    3.0  0.0  3.0  \n",
      "4    1.0  0.0  3.0  \n",
      "balance: 0.5387205387205387\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "# Let's load the data - 0 points for this because they had to do it during the exam\n",
    "feature_names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach',\\\n",
    "                'exang','oldpeak','slope','ca','thal']\n",
    "label = 'num'\n",
    "df = pd.read_csv('data/cleveland.data',header=None)\n",
    "df.columns = feature_names + [label] \n",
    "\n",
    "df.replace(to_replace='?',value = np.nan, inplace=True) # replace '?' with nans\n",
    "df.dropna(inplace=True) \n",
    "df.reset_index(drop=True, inplace=True) \n",
    "\n",
    "y = df[label]\n",
    "df.drop(columns=[label],inplace=True)\n",
    "print(df.head()) # 1 point for separating X and y\n",
    "\n",
    "classes, counts = np.unique(y,return_counts=True)\n",
    "\n",
    "print('balance:',np.max(counts/len(y))) # 1 point for calculating the balance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1b) ML pipeline with logistic regression\n",
    "\n",
    "Split your data in a stratified manner into `other` and `test` (20% in `test`) and then split `other` into 5 stratified folds. 4 of those folds will be used for training, the last fold will be CV. You'll need to loop through the 5 options the CV fold can be selected. (4 points)\n",
    "\n",
    "Preprocess the data. Apply the OneHotEncoder and the StandardScaler to the appropriate columns. Make sure to fit_transform only train (4 out of the 5 folds). The CV and test sets should be transformed based on the preprocessor fitted to train. (2 points)\n",
    "\n",
    "Train a logistic regression model with l1 regularization and tune the appropriate parameter. (4 points)\n",
    "\n",
    "Repeat the procedure 10 times with 10 different random states and print the mean and std of the test accuracy score. Make sure to print the best parameters and check that the best values are not at the edge of your parameter space if possible. Check that your code is reproducable! That is, if you rerun the cell, you get back the exact same result. (3 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 20)\n",
      "{'logisticregression__C': 0.3}\n",
      "CV score: 0.5907172995780591\n",
      "test score: 0.55\n",
      "{'logisticregression__C': 3}\n",
      "CV score: 0.5907172995780591\n",
      "test score: 0.6\n",
      "{'logisticregression__C': 0.3}\n",
      "CV score: 0.5864978902953587\n",
      "test score: 0.5666666666666667\n",
      "{'logisticregression__C': 0.3}\n",
      "CV score: 0.5907172995780591\n",
      "test score: 0.5666666666666667\n",
      "{'logisticregression__C': 0.3}\n",
      "CV score: 0.6033755274261603\n",
      "test score: 0.5833333333333334\n",
      "{'logisticregression__C': 0.3}\n",
      "CV score: 0.6075949367088608\n",
      "test score: 0.5833333333333334\n",
      "{'logisticregression__C': 0.3}\n",
      "CV score: 0.5780590717299579\n",
      "test score: 0.5833333333333334\n",
      "{'logisticregression__C': 0.3}\n",
      "CV score: 0.5907172995780591\n",
      "test score: 0.5666666666666667\n",
      "{'logisticregression__C': 0.3}\n",
      "CV score: 0.5864978902953587\n",
      "test score: 0.6333333333333333\n",
      "{'logisticregression__C': 0.3}\n",
      "CV score: 0.6033755274261603\n",
      "test score: 0.6\n",
      "0.5833333333333333 0.022360679774997883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cat_features = ['cp','slope','thal']\n",
    "\n",
    "ct = make_column_transformer((OneHotEncoder(sparse=False,handle_unknown='ignore'), cat_features),\n",
    "                             remainder=StandardScaler()) # 2 points\n",
    "\n",
    "print(np.shape(ct.fit_transform(df)))\n",
    "\n",
    "pipe = make_pipeline(ct, LogisticRegression(penalty='l1',solver='saga',max_iter=10000,multi_class='auto')) # 1 point\n",
    "\n",
    "param_grid = {'logisticregression__C': [0.01,0.03,0.1,0.3,1,3]} # 1 point\n",
    "\n",
    "def fit(df, y, random_state):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(df, y, random_state=random_state, test_size=0.2, stratify=y) # 2 points\n",
    "    kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=random_state) # 2 points\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,\n",
    "                        cv=kf, return_train_score=True,iid=True) # 2 points\n",
    "    grid.fit(X_other, y_other)\n",
    "    print(grid.best_params_)# 1 point for printing best params\n",
    "    print('CV score:',grid.best_score_) \n",
    "    print('test score:',grid.score(X_test, y_test))\n",
    "    return grid.score(X_test, y_test)\n",
    "\n",
    "test_scores = []\n",
    "for i in range(10): # 1 point\n",
    "    test_score = fit(df,y,i*42)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "print(np.mean(test_scores),np.std(test_scores)) # 1 point\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1d) Train a random forest classifier and tune the appropriate parameters. Make sure to print the best parameters and check that the best values are not at the edge of your parameter space if possible. Repeat the procedure 10 times with 10 different random states and print the mean and std of the test accuracy score. Check that your code is reproducable! That is, if you rerun the cell, you get back the exact same result. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__max_depth': 10, 'randomforestclassifier__min_samples_split': 16}\n",
      "CV score: 0.5780590717299579\n",
      "test score: 0.55\n",
      "{'randomforestclassifier__max_depth': 10, 'randomforestclassifier__min_samples_split': 8}\n",
      "CV score: 0.5949367088607594\n",
      "test score: 0.5833333333333334\n",
      "{'randomforestclassifier__max_depth': 3, 'randomforestclassifier__min_samples_split': 4}\n",
      "CV score: 0.5780590717299579\n",
      "test score: 0.5833333333333334\n",
      "{'randomforestclassifier__max_depth': 3, 'randomforestclassifier__min_samples_split': 16}\n",
      "CV score: 0.5907172995780591\n",
      "test score: 0.5666666666666667\n",
      "{'randomforestclassifier__max_depth': 10, 'randomforestclassifier__min_samples_split': 8}\n",
      "CV score: 0.5864978902953587\n",
      "test score: 0.5833333333333334\n",
      "{'randomforestclassifier__max_depth': 10, 'randomforestclassifier__min_samples_split': 16}\n",
      "CV score: 0.5864978902953587\n",
      "test score: 0.5833333333333334\n",
      "{'randomforestclassifier__max_depth': 30, 'randomforestclassifier__min_samples_split': 4}\n",
      "CV score: 0.5907172995780591\n",
      "test score: 0.5666666666666667\n",
      "{'randomforestclassifier__max_depth': 3, 'randomforestclassifier__min_samples_split': 8}\n",
      "CV score: 0.5822784810126582\n",
      "test score: 0.6333333333333333\n",
      "{'randomforestclassifier__max_depth': 10, 'randomforestclassifier__min_samples_split': 2}\n",
      "CV score: 0.6118143459915611\n",
      "test score: 0.5166666666666667\n",
      "{'randomforestclassifier__max_depth': 10, 'randomforestclassifier__min_samples_split': 4}\n",
      "CV score: 0.6118143459915611\n",
      "test score: 0.5166666666666667\n",
      "0.5683333333333334 0.03287180487219335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'randomforestclassifier__max_depth': [1,3,10,30],\n",
    "             'randomforestclassifier__min_samples_split': [2,4,8,16]} # 2 points\n",
    "\n",
    "def fit(df, y, random_state):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(df, y, random_state=random_state, test_size=0.2, stratify=y) # 2 points\n",
    "    kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "    # RandomForestClassifier needs to be defined inside the function, random state needs to be set.\n",
    "    pipe = make_pipeline(ct, RandomForestClassifier(n_estimators=100,random_state=random_state)) # 2 points\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,\n",
    "                        cv=kf, return_train_score=True,iid=True) \n",
    "    grid.fit(X_other, y_other)\n",
    "    print(grid.best_params_)# 1 point for printing best params\n",
    "    print('CV score:',grid.best_score_) \n",
    "    print('test score:',grid.score(X_test, y_test))\n",
    "    return grid.score(X_test, y_test)\n",
    "\n",
    "test_scores = []\n",
    "for i in range(10): \n",
    "    test_score = fit(df,y,i*42)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "print(np.mean(test_scores),np.std(test_scores)) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1e) Train an SVC and tune the appropriate parameters. Make sure to print the best parameters and check that the best values are not at the edge of your parameter space if possible. Repeat the procedure 10 times with 10 different random states and print the mean and std of the test accuracy score. Check that your code is reproducable! That is, if you rerun the cell, you get back the exact same result. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "CV score: 0.5822784810126582\n",
      "test score: 0.6166666666666667\n",
      "{'svc__C': 1, 'svc__gamma': 0.1}\n",
      "CV score: 0.5907172995780591\n",
      "test score: 0.5833333333333334\n",
      "{'svc__C': 1000, 'svc__gamma': 0.001}\n",
      "CV score: 0.5654008438818565\n",
      "test score: 0.5666666666666667\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "CV score: 0.6075949367088608\n",
      "test score: 0.6\n",
      "{'svc__C': 100, 'svc__gamma': 0.01}\n",
      "CV score: 0.620253164556962\n",
      "test score: 0.5\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "CV score: 0.5949367088607594\n",
      "test score: 0.55\n",
      "{'svc__C': 100, 'svc__gamma': 0.1}\n",
      "CV score: 0.5907172995780591\n",
      "test score: 0.5166666666666667\n",
      "{'svc__C': 10, 'svc__gamma': 0.01}\n",
      "CV score: 0.569620253164557\n",
      "test score: 0.55\n",
      "{'svc__C': 10, 'svc__gamma': 0.01}\n",
      "CV score: 0.5864978902953587\n",
      "test score: 0.6166666666666667\n",
      "{'svc__C': 1, 'svc__gamma': 0.1}\n",
      "CV score: 0.6244725738396625\n",
      "test score: 0.5333333333333333\n",
      "0.5633333333333335 0.038586123009300755\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = make_pipeline(ct, SVC(kernel='rbf')) # 1 point\n",
    "\n",
    "param_grid = {'svc__C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000]} # 2 points\n",
    "\n",
    "def fit(df, y, random_state):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(df, y, random_state=random_state, test_size=0.2, stratify=y) # 2 points\n",
    "    kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=random_state) \n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,\n",
    "                        cv=kf, return_train_score=True,iid=True) # 1 points\n",
    "    grid.fit(X_other, y_other)\n",
    "    print(grid.best_params_)# 1 point for printing best params\n",
    "    print('CV score:',grid.best_score_) \n",
    "    print('test score:',grid.score(X_test, y_test))\n",
    "    return grid.score(X_test, y_test)\n",
    "\n",
    "test_scores = []\n",
    "for i in range(10): # 1 point\n",
    "    test_score = fit(df,y,i*42)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "print(np.mean(test_scores),np.std(test_scores)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1f) Compare the means and standard deviations of the three techniques. How many standard deviations above the baseline accuracy are the three models? How would you rank them with respect of accuracy? (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic regression: 0.58 +/- 0.02\n",
    "- Random forest: 0.57 +/- 0.03\n",
    "- SVC: 0.56 +/- 0.04\n",
    "\n",
    "The balance is 0.54 and we did stratified splits so the same balance holds for each set. So the methods are 2, 1 and 0.5 sigmas above the baseline (actual numbers might vary because of random seeds). 2 points\n",
    "\n",
    "Based on this, maybe logistic regression is better than the other two techniques but not by much. 1 point \n",
    "\n",
    "The results might vary because the different random states students might choose. Please check that their conclusions are correct based on their findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
